{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c9e802c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Noval.DESKTOP-G118GKA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import library yang dibutuhkan\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ec4f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfigurasi parameter untuk model dan data\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "DATASET_DIR = 'batik_jogja' # Pastikan folder ini ada di direktori yang sama\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 10 # Anda bisa menambahkannya untuk akurasi yang lebih baik\n",
    "\n",
    "# URL model EfficientNet-Lite0 dari TensorFlow Hub\n",
    "HUB_MODEL_URL = \"https://tfhub.dev/tensorflow/efficientnet/lite0/feature-vector/2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2667013d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memuat dataset dari direktori...\n",
      "Found 1350 files belonging to 6 classes.\n",
      "Using 1080 files for training.\n",
      "Found 1350 files belonging to 6 classes.\n",
      "Using 270 files for validation.\n",
      "\n",
      "Kelas yang ditemukan: ['batik_ceplok' 'batik_kawung' 'batik_nitik' 'batik_parang'\n",
      " 'batik_sidoluhur' 'batik_truntum']\n"
     ]
    }
   ],
   "source": [
    "print(\"Memuat dataset dari direktori...\")\n",
    "\n",
    "# Dataset untuk training (80% dari data)\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATASET_DIR,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Dataset untuk validasi (20% dari data)\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATASET_DIR,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Simpan nama kelas\n",
    "class_names = np.array(train_dataset.class_names)\n",
    "num_classes = len(class_names)\n",
    "print(\"\\nKelas yang ditemukan:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae5b4110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset siap digunakan.\n"
     ]
    }
   ],
   "source": [
    "# Menggunakan cache dan prefetch untuk mempercepat loading data saat training\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"\\nDataset siap digunakan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "552e7d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membangun model Keras dengan base model dari TensorFlow Hub...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer 'efficientnet_lite0_base' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None, 224, 224, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor>,) and kwargs: {} for signature: (images: TensorSpec(shape=(None, None, None, 3), dtype=tf.float32, name='images')) -> Dict[['default', TensorSpec(shape=(None, 1280), dtype=tf.float32, name=None)]].\nFallback to flat signature also failed due to: pruned(images): expected argument #0(zero-based) to be a Tensor; got KerasTensor (<KerasTensor shape=(None, 224, 224, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor>).\n\nCall arguments received by layer 'efficientnet_lite0_base' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None, 224, 224, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor>\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39mIMG_SIZE \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m3\u001b[39m,))\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 2. Hubungkan input ke base model dari TensorFlow Hub\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_extractor_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 3. Tambahkan lapisan Dropout setelahnya\u001b[39;00m\n\u001b[0;32m     21\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.2\u001b[39m)(x)\n",
      "File \u001b[1;32mc:\\Users\\Noval.DESKTOP-G118GKA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Noval.DESKTOP-G118GKA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:242\u001b[0m, in \u001b[0;36mKerasLayer.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# ...but we may also have to pass a Python boolean for `training`, which\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# is the logical \"and\" of this layer's trainability and what the surrounding\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# model is doing (analogous to keras.layers.BatchNormalization in TF2).\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# For the latter, we have to look in two places: the `training` argument,\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# or else Keras' global `learning_phase`, which might actually be a tensor.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_training_argument:\n\u001b[1;32m--> 242\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable:\n",
      "\u001b[1;31mTypeError\u001b[0m: Exception encountered when calling layer 'efficientnet_lite0_base' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None, 224, 224, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor>,) and kwargs: {} for signature: (images: TensorSpec(shape=(None, None, None, 3), dtype=tf.float32, name='images')) -> Dict[['default', TensorSpec(shape=(None, 1280), dtype=tf.float32, name=None)]].\nFallback to flat signature also failed due to: pruned(images): expected argument #0(zero-based) to be a Tensor; got KerasTensor (<KerasTensor shape=(None, 224, 224, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor>).\n\nCall arguments received by layer 'efficientnet_lite0_base' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None, 224, 224, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor>\n  • training=None"
     ]
    }
   ],
   "source": [
    "# Cell 5: Membangun Model (Lengkap)\n",
    "\n",
    "print(\"Membangun model Keras dengan base model dari TensorFlow Hub...\")\n",
    "\n",
    "# Lapisan ini akan mengambil model EfficientNet-Lite0 dan tidak akan dilatih ulang (trainable=False)\n",
    "feature_extractor_layer = hub.KerasLayer(\n",
    "    HUB_MODEL_URL,\n",
    "    trainable=False, \n",
    "    name='efficientnet_lite0_base',\n",
    "    input_shape=IMG_SIZE + (3,)\n",
    ")\n",
    "\n",
    "# --- BLOK YANG ANDA GANTI (INI SUDAH BENAR) ---\n",
    "# 1. Definisikan layer input secara eksplisit\n",
    "inputs = tf.keras.Input(shape=IMG_SIZE + (3,))\n",
    "\n",
    "# 2. Hubungkan input ke base model dari TensorFlow Hub\n",
    "x = feature_extractor_layer(inputs)\n",
    "\n",
    "# 3. Tambahkan lapisan Dropout setelahnya\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "# 4. Tambahkan lapisan output akhir\n",
    "outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name='output_layer')(x)\n",
    "\n",
    "# 5. Buat model dengan mendefinisikan input dan outputnya\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "# --- AKHIR BLOK PENGGANTI ---\n",
    "\n",
    "# Tampilkan ringkasan arsitektur model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kompilasi model dengan optimizer, loss function, dan metrik\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Mulai proses pelatihan\n",
    "print(f\"\\nMemulai pelatihan model untuk {EPOCHS} epoch...\")\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4283f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengambil data histori pelatihan\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "# Membuat plot untuk Akurasi\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Membuat plot untuk Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Tampilkan plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47be15c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan model yang sudah dilatih ke dalam file .h5\n",
    "NEW_MODEL_PATH = 'batik_lite_model.h5'\n",
    "print(f\"\\nMenyimpan model yang telah dilatih ke '{NEW_MODEL_PATH}'...\")\n",
    "\n",
    "model.save(NEW_MODEL_PATH)\n",
    "\n",
    "print(\"Model baru berhasil disimpan!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
